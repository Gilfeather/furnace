# Furnace Examples

This directory contains examples demonstrating how to use Furnace with different types of models and scenarios.

## ğŸš€ Quick Start

### If you already have a .mpk model file:
```bash
# Just run Furnace directly
./furnace --model-path /path/to/your/model.mpk
```

### If you need a sample model for testing:
```bash
# 1. Create a sample model
cargo run --example basic_mnist_create

# 2. Start the server
cargo run --bin furnace -- --model-path examples/basic_mnist/model.mpk

# 3. Test inference
cargo run --example basic_mnist_test
```

## ğŸ“¦ Getting .mpk Model Files

Furnace uses Burn's MessagePack (.mpk) format. You can obtain .mpk files from:

### ğŸ”¥ **From Burn Training Scripts**
```rust
// In your Burn training code
use burn::record::CompactRecorder;

// After training your model
let recorder = CompactRecorder::new();
model.save_file("my_model", &recorder)?; // Creates my_model.mpk
```

### ğŸ“¥ **From Model Repositories**
- **[Burn Examples](https://github.com/tracel-ai/burn/tree/main/examples)**: Official Burn examples with pre-trained models
- **[Burn Book](https://burn.dev/book/)**: Official documentation with model examples  
- **[Hugging Face](https://huggingface.co/models?library=burn)**: Models converted to Burn format
- **[Burn Community](https://github.com/tracel-ai/burn/discussions)**: Community-shared models and discussions
- **Your own trained models**

### ğŸ› ï¸ **Converting from Other Formats**
- **ONNX â†’ Burn**: Using burn-import tool
- **PyTorch â†’ Burn**: Via ONNX conversion (see [ONNX conversion guide](onnx_conversion/README.md))
- **TensorFlow â†’ Burn**: Via ONNX conversion

**Step-by-step conversion example:**
```bash
# 1. Install dependencies
pip install torch torchvision onnx onnxruntime
cargo install burn-import

# 2. Export PyTorch to ONNX
python examples/onnx_conversion/pytorch_to_onnx.py

# 3. Convert ONNX to Burn
burn-import --input simple_mlp.onnx --output simple_mlp_burn

# 4. Use with Furnace
./furnace --model-path simple_mlp_burn.mpk
```

### ğŸ§ª **For Testing/Development**
- Use our example creation scripts (see below)
- Generate synthetic models for testing

## Available Examples

### ğŸ¯ Basic MNIST Example (`basic_mnist/`)

**Purpose**: Demonstrates basic Furnace usage with a simple MLP model

**What it creates**:
- Simple MLP model (784â†’128â†’10) for MNIST-like data
- Model saved in .mpk format
- Metadata file with model specifications

**When to use**: 
- âœ… Testing Furnace functionality
- âœ… Learning how Burn models work
- âœ… Development and debugging
- âŒ Production use (use your trained models instead)

### ğŸ”„ ONNX Conversion Example (`onnx_conversion/`)

**Purpose**: Convert existing PyTorch/TensorFlow models to Burn format for production use

**What it demonstrates**:
- PyTorch â†’ ONNX â†’ Burn conversion pipeline
- Production-ready model conversion (ResNet-18, etc.)
- Testing and validation of converted models
- Complete step-by-step conversion guide

**When to use**:
- âœ… **Production use** with existing trained models
- âœ… Converting models from other frameworks
- âœ… Using pre-trained models (ImageNet, etc.)
- âœ… Real-world deployment scenarios

**Quick start**:
```bash
# 1. Export PyTorch models to ONNX
python examples/onnx_conversion/pytorch_to_onnx.py

# 2. Convert ONNX to Burn
burn-import --input simple_mlp.onnx --output simple_mlp_burn

# 3. Use with Furnace
./furnace --model-path simple_mlp_burn.mpk
```

## Example Structure

Each example follows this structure:
```
examples/
â”œâ”€â”€ example_name/
â”‚   â”œâ”€â”€ README.md          # Detailed instructions
â”‚   â”œâ”€â”€ model.mpk          # Generated model file (gitignored)
â”‚   â”œâ”€â”€ model.json         # Generated metadata (gitignored)
â”‚   â””â”€â”€ data/              # Generated data files (gitignored)
â”œâ”€â”€ example_name_create.rs # Model creation script
â”œâ”€â”€ example_name_test.rs   # Inference testing script
â””â”€â”€ README.md              # This file
```

## Key Features Demonstrated

- âœ… **Model Creation**: How to create and save Burn models
- âœ… **Multiple Formats**: Support for .burn and .mpk formats
- âœ… **HTTP API**: Complete inference API testing
- âœ… **Error Handling**: Input validation and error responses
- âœ… **Performance**: Timing and throughput testing
- âœ… **Structured Logging**: Development and production logging
- âœ… **Configuration**: Different server configurations

## Development Notes

- **Model files** (.mpk, .burn) are generated at runtime and not tracked in git
- **Data files** are also generated and gitignored to keep the repository clean
- **Examples are self-contained** - each can run independently
- **Comprehensive testing** - each example includes validation and error testing

## Adding New Examples

To add a new example:

1. Create a new directory: `examples/your_example/`
2. Add a README.md with instructions
3. Create `your_example_create.rs` for model creation
4. Create `your_example_test.rs` for testing
5. Update this README.md

Make sure to:
- Add model files to .gitignore
- Include comprehensive error testing
- Document the model architecture and use case
- Provide clear usage instructions